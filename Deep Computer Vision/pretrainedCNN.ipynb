{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained models and fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PRETRAINED MODEL: We can use a pretrained CNN, at the star of our model. This allow us to have a very good convolutional base before adding our own dense layeres classifier at the end. By using this technique we can train a very good classifier for a realtively small dataset ( < 10000 images )\n",
    "- FINE TUNING: We want to tweak the final layers in our convolutional base to work better for our specific problem. This involves not touching or retraining the earlier layers in the convolutional base but only adjusting the final few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs', #nombre del dataset que se quiere cargar\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'], #80%entrenamiento, 10%validacion, 10%prueba\n",
    "    with_info=True, #info adicional del dataset en el entorno, como los nombres de las clases y estadisticas\n",
    "    as_supervised=True, #carga los datos en formato de a pares en lugar de un formato no supervisado\n",
    "    shuffle_files=True #baraja los archivos del dataset antes de cargarlos para mejorar la generalizacion del modelo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_name = metadata.features['label'].int2str #creates a function object that we can use to get labels\n",
    "\n",
    "#display 2 images from the dataset\n",
    "for image, label in raw_train.take(2):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(get_label_name(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the sizes of our images are all different, we need to convert them all to the same size. We create a function that will do that for us below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160\n",
    "\n",
    "def format_example (image, label):\n",
    "    \"\"\"\n",
    "    returns an image that it reshaped to IMG_SIZE\n",
    "    \"\"\"\n",
    "\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply this function to all our images using map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the images reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train.take(2):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(get_label_name(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will shuffle and batch the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "\n",
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look at the shape of an original image vs the new image we will see it has been changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img,label in raw_train.take(2):\n",
    "    print(\"original shape: \", img.shape)\n",
    "\n",
    "for img, label in train.take(2):\n",
    "    print ('new shape', img.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be used as the concolutional base for our model is the MobileNet V2 developed at Google. This model is trained on 1.4 millions images and has 1000 different classes.\n",
    "\n",
    "We want to use this model but only its convolutional base. So when we load in the model we'll specify that we don't want to load the top classification layer. We'll tell the model what input shape to expect and to use the predetermined weights from imagenet. (Google dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "#Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2 (input_shape=IMG_SHAPE, #tamanio de las imagenes\n",
    "                                                include_top = False, #se debe exluuir la capa superior del modelo original de MobileNetV2, que es la capa de clasificacion final\n",
    "                                                weights = 'imagenet') #se deben cargar los pesos preentrenados del modelo que han sido entrenados previamente en el conjunto de datos ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, _ in train_batches.take(1): #train_batches es un datast de tensorflow que contiene lotes de imagenes y sus etiquetas, toma el primer lote del ds\n",
    "    pass #tera sobre el primer lote del dataset. Aquí, image representa un lote de imágenes, y _ es una variable que representa las etiquetas asociadas, que no se utilizan en este fragmento de código.\n",
    "\n",
    "feature_batch = base_model(image) #pasa el lote de imagenes a traves del modelo preentrenado MobileNetV2 (sin la capa superior)\n",
    "print(feature_batch.shape) #Imprime la forma del tensor feature_batch. La forma típica de estas características es (batch_size, height, width, channels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freezing the Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term freezing refers to disabling the training property of a layer. It simply means we wont make any changes to the weights of any layers that are frozen during training.\n",
    "- This is important as we don't want to change the convolutional base that already has learned weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding our classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our base layer setup we can add the classifier. Instead of flattening the feature map of the base layer we will use a global average pooling layer that will average the entire 5x5 area of each 2D feature map and return to us a single 1280 element vector per filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will add the prediction layer that will be a single dense neuron. We can do this because we only have two classes to predict for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will combine these layers together in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    global_average_layer,\n",
    "    prediction_layer\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train and compile the model. We will use a very small learning rate to ensure that the model does not have any major changes made to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss= tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can evaluate the model right now to see how it does before training it on our new images\n",
    "\n",
    "initial_epochs = 3\n",
    "validation_steps = 20\n",
    "\n",
    "loss0, accuracy0 = model.evaluate(validation_batches, steps= validation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can train it on our images\n",
    "\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data = validation_batches)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the model in keras like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dogs_vs_cats.h5')\n",
    "new_model = tf.keras.models.load_model('dogs_vs_cats.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
